* MultitaskAIS online

Goal: Evaluate how MultitaskAIS can be used to detect abnormal tracks in a
      stream of messages

** Runtimes

Runtimes are available through some docker images: 

- ~base~ image: contains the multitaskAIS dependencies (using Conda) and the MultitaskAIS 
  source code.

- ~stream~ image: contains the code of an operator detecting "abnormal" 
  tracks in an AIS messages. At runtime this assumes that AIS message are
  ingested through Kafka and available on a topic keyed by mmsi.

- ~tracks~ image: contains the code that build tracks from a set of ais messages.
  This works offline with an already known set of messages. Those tracks can be
  used as input to benchmark the detection function.


*** Build

To build the images you need to set the ~NAMESPACE~ and ~TARGET_REF~
environment variables. You need to use the MultitaskAIS root directory as the
context directory of the build.


- Get the code:
#+BEGIN_SRC bash
# one time
git clone https://github.com/msimonin/MultitaskAIS.git -b online_detection
cd MultitaskAIS
#+END_SRC

- Setup docker on g5k
#+BEGIN_SRC bash
# one time on g5k
/grid5000/code/bin/g5k-setup-docker
# get more space for the docker images
sudo-g5k sed -E -i "s/ExecStart=\/usr\/bin\/dockerd (.*)/ExecStart=\/usr\/bin\/dockerd --data-root=\/tmp\/docker \\1/" /lib/systemd/system/docker.service
s
sudo-g5k systemctl daemon-reload
sudo-g5k service docker restart
which docker
ls /srv/storage/sesame@storage1.rennes
#+END_SRC

- Build the images 
#+BEGIN_SRC bash
# Image build example
export NAMESPACE=sesame
export TARGET_REF=1.0.0
# base
docker build -f docker/base/Dockerfile . -t $NAMESPACE/multitaskais_base:$TARGET_REF
# stream
docker build --build-arg NAMESPACE=$NAMESPACE --build-arg TARGET_REF=$TARGET_REF -f docker/stream/Dockerfile . -t $NAMESPACE/multitaskais_stream:$TARGET_REF
# tracks
docker build --build-arg NAMESPACE=$NAMESPACE --build-arg TARGET_REF=$TARGET_REF -f docker/tracks/Dockerfile . -t $NAMESPACE/multitaskais_tracks:$TARGET_REF
#+END_SRC

*** Evaluation

**** Build all the tracks

For each year this creates all the tracks on a dedicated nodes. 
Depending on the year it took approx 32 CPU x 6 hours. 

#+BEGIN_SRC python :tangle build_tracks.py
from enoslib.api import play_on, __default_python3__, __docker__
from enoslib.infra.enos_g5k.provider import G5k
from enoslib.infra.enos_g5k.configuration import Configuration, NetworkConfiguration

import logging
import os

logging.basicConfig(level=logging.INFO)


YEARS = [f"201{i}" for i in range(1, 9)]

# claim the resources
network = NetworkConfiguration(
    id="n1",
    type="prod",
    roles=["my_network"],
    site="rennes"
)
conf = (
    Configuration
    .from_settings(job_name="build_tracks",
                   job_type="allow_classic_ssh",
                   walltime="11:00:00")
    .add_network_conf(network)
    .add_machine(
        roles=["control"],
        cluster="paravance",
        nodes=len(YEARS),
        primary_network=network
    )
    .finalize()
)

provider = G5k(conf)
roles, _ = provider.init()
print(roles)

with play_on(roles=roles, priors=[__default_python3__, __docker__]) as p:
    p.lineinfile(
        path="/lib/systemd/system/docker.service",
        regexp="ExecStart=/usr/bin/dockerd (.*)",
        # NOTE: Yaml requires escaping backslashes in double quotes but not in single quotes
        line="ExecStart=/usr/bin/dockerd --data-root=/tmp/docker \\1",
        backrefs="yes"
    )
    p.systemd(
        name="docker",
        state="restarted",
        daemon_reload="yes"
    )
    p.apt(name="python3-pip", state="present")
    p.pip(name="docker", state="present")
    p.shell("ls /srv/storage/sesame@storage1.rennes")

for host, year in zip(roles["control"], YEARS):
    # inject host level vars
    host.extra.update(year=year)

with play_on(roles=roles) as p:
    # copy locally the source dir
    p.shell("rsync -avz /srv/storage/sesame@storage1.rennes/sesame/ais_britany/raw/{{ year }} /tmp/")
    # build tracks for the given year
    p.docker_container(
        name="multitaskais_tracks",
        image="registry.gitlab.inria.fr/sesame/platform/multitaskais_tracks:1.0.14",
        state="started",
        volumes=[
            "/tmp/{{ year }}:/data",
            "/tmp/result/{{ year }}:/tmp/trajectories"
        ],
        command="--master 'local[{{ ansible_processor_vcpus }}]' main.py /data/*/*/*.cdv brittany"
    )
#+END_SRC

**** Save the tracks


#+BEGIN_SRC python :tangle save_tracks.py
# TODO merge with build_tracks
from enoslib.api import play_on, __default_python3__, __docker__
from enoslib.infra.enos_g5k.provider import G5k
from enoslib.infra.enos_g5k.configuration import Configuration, NetworkConfiguration

import logging
import os

logging.basicConfig(level=logging.INFO)


YEARS = [f"201{i}" for i in range(1, 9)]

# claim the resources
network = NetworkConfiguration(
    id="n1",
    type="prod",
    roles=["my_network"],
    site="rennes"
)
conf = (
    Configuration
    .from_settings(job_name="build_tracks",
                   job_type="allow_classic_ssh",
                   walltime="11:00:00")
    .add_network_conf(network)
    .add_machine(
        roles=["control"],
        cluster="paravance",
        nodes=len(YEARS),
        primary_network=network
    )
    .finalize()
)

provider = G5k(conf)
roles, _ = provider.init()
print(roles)

for host, year in zip(roles["control"], YEARS):
    # inject host level vars
    host.extra.update(year=year)

with play_on(roles=roles) as p:
    # copy locally the source dir
    target = "/srv/storage/sesame@storage1.rennes/sesame/generated/multitaskais"
    p.shell(f"mkdir -p {target}")
    p.shell("rsync -avz /tmp/result/{{ year }} %s" % target)
#+END_SRC

**** TODO Benchmark the alert function
